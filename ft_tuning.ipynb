{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code explores using fastText for sentiment analysis and how different hyperparameters affect accuracy of the trained models. <br>\n",
        "The datasets in this example are from https://www.kaggle.com/datasets/bittlingmayer/amazonreviews. <br>\n",
        "See https://fasttext.cc/docs/en/supervised-tutorial.html for more information on installing and using fastText. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first section can easily be run in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if running in Colab uncomment next line\n",
        "#! pip install fastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XwlWang4iXjA"
      },
      "outputs": [],
      "source": [
        "import fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For Colab, download/upload datasets (and unzip if needed)\n",
        "# if running locally, copy datasets to project folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MekQhbzEii8_"
      },
      "outputs": [],
      "source": [
        "# train model with default hyperparameters\n",
        "model = fasttext.train_supervised(input=\"train.ft.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTdd3zfYin4E",
        "outputId": "228ad3a9-a6d1-4365-95f3-6932cee2eb11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400000, 0.915915, 0.915915)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# output is: (# of reviews in test set, precision, recall)\n",
        "model.test(\"test.ft.txt\", k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBAsSs73_8HX",
        "outputId": "4fb3a2ac-f868-43a5-f9ec-00fb353d927c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'__label__2': {'precision': 0.9126468370505596,\n",
              "  'recall': nan,\n",
              "  'f1score': 1.8252936741011192},\n",
              " '__label__1': {'precision': 0.9192353439238771,\n",
              "  'recall': nan,\n",
              "  'f1score': 1.8384706878477541}}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# a deeper look into the accuracy of the model\n",
        "model.test_label(\"test.ft.txt\", k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('__label__2',), array([1.00000441]))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test positive review (__label__2)\n",
        "model.predict(\"This product is amazing\", k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('__label__1',), array([1.00001001]))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test negative review (__label__1)\n",
        "model.predict(\"This product is terrible\", k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('__label__2',), array([0.99545562]))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test mixed sentiment, but should be negative (__label__1)\n",
        "model.predict(\"I wish I could say this product was great\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "p7Tmx1n8iqic"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400000, 0.93731, 0.93731)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# \"out of the box\" model doesn't do well with mixed sentiment, try with bigrams\n",
        "model2 = fasttext.train_supervised(input=\"train.ft.txt\", wordNgrams=2)\n",
        "model2.test(\"test.ft.txt\", k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('__label__1',), array([0.55281043]))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test mixed sentiment, but should be negative (__label__1)\n",
        "model2.predict(\"I wish I could say this product was great\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EZTCwp7BCFcr"
      },
      "outputs": [],
      "source": [
        "# let's see how changing learning rate from default (.1) to 0.05 changes accuracy\n",
        "model2_1 = fasttext.train_supervised(input=\"train.ft.txt\", lr=0.05, wordNgrams=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo7-8UYCCQR3",
        "outputId": "2bd3b6fa-8be8-4f2d-e74f-b605a76bb711"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400000, 0.93826, 0.93826)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2_1.test(\"test.ft.txt\", k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ceg-lKmfKAKa",
        "outputId": "85272314-357d-4704-cdad-ca712995eb7d"
      },
      "outputs": [],
      "source": [
        "# a slight improvement, let's increase # epochs from default (5) to 10\n",
        "model2_2 = fasttext.train_supervised(input=\"train.ft.txt\", epoch=10, lr=0.05, wordNgrams=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_Ttu6gYKAq-",
        "outputId": "ddcbfd24-e54f-426c-84f1-478e8c2b4873"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400000, 0.93386, 0.93386)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2_2.test(\"test.ft.txt\", k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xBdbnWqytDMI"
      },
      "outputs": [],
      "source": [
        "# that was slightly worse, let's try 4-grams\n",
        "model3 = fasttext.train_supervised(input=\"train.ft.txt\", epoch = 10, wordNgrams=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLS7hrRgtH_7",
        "outputId": "38b1c0f0-d83d-435e-d342-bf00ec25fb75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400000, 0.926095, 0.926095)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model3.test(\"test.ft.txt\", k=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tuning the hyperparameters manually is quite time consuming. Thankfully, fastText comes with autotuning. <br>\n",
        "See https://fasttext.cc/docs/en/autotune.html for more info on automatic hyperparameter optimization. <br>\n",
        "It is recommended to run the following code in a local environment to avoid Colab timeouts and memory usage errors.<br>\n",
        "Below, we run autotune for 1, 2, and 3 hour blocks and see what hyperparameters fastText finds as optimal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjU-DjXoz86P",
        "outputId": "950e664c-c0ea-4979-bef3-7fbbe07f074c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400000, 0.94062, 0.94062)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1 hour optimization\n",
        "model4 = fasttext.train_supervised(input='train.ft.txt', autotuneValidationFile='test.ft.txt', autotuneDuration=3600)\n",
        "model4.test(\"test.ft.txt\", k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "autotuneDuration -> 3600\n",
            "autotuneMetric -> f1\n",
            "autotuneModelSize -> \n",
            "autotunePredictions -> 1\n",
            "autotuneValidationFile -> test.ft.txt\n",
            "bucket -> 10000000\n",
            "cutoff -> 0\n",
            "dim -> 52\n",
            "dsub -> 2\n",
            "epoch -> 30\n",
            "input -> train.ft.txt\n",
            "label -> __label__\n",
            "loss -> loss_name.softmax\n",
            "lr -> 0.04519001700813223\n",
            "lrUpdateRate -> 100\n",
            "maxn -> 0\n",
            "minCount -> 1\n",
            "minCountLabel -> 0\n",
            "minn -> 0\n",
            "model -> model_name.supervised\n",
            "neg -> 5\n",
            "output -> \n",
            "pretrainedVectors -> \n",
            "qnorm -> False\n",
            "qout -> False\n",
            "retrain -> False\n",
            "saveOutput -> False\n",
            "seed -> 0\n",
            "setManual -> <bound method PyCapsule.setManual of <fasttext_pybind.args object at 0x000001751783AB70>>\n",
            "t -> 0.0001\n",
            "thread -> 15\n",
            "verbose -> 2\n",
            "wordNgrams -> 4\n",
            "ws -> 5\n"
          ]
        }
      ],
      "source": [
        "# below method of obtaining hyperparameter attributes was found at https://github.com/facebookresearch/fastText/issues/887\n",
        "args_obj = model4.f.getArgs()\n",
        "for hparam in dir(args_obj):\n",
        "    if not hparam.startswith('__'):\n",
        "        print(f\"{hparam} -> {getattr(args_obj, hparam)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400000, 0.9430025, 0.9430025)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2 hour optimization\n",
        "model5 = fasttext.train_supervised(input='train.ft.txt', autotuneValidationFile='test.ft.txt', autotuneDuration=7200)\n",
        "model5.test(\"test.ft.txt\", k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "autotuneDuration -> 7200\n",
            "autotuneMetric -> f1\n",
            "autotuneModelSize -> \n",
            "autotunePredictions -> 1\n",
            "autotuneValidationFile -> test.ft.txt\n",
            "bucket -> 10000000\n",
            "cutoff -> 0\n",
            "dim -> 65\n",
            "dsub -> 8\n",
            "epoch -> 15\n",
            "input -> train.ft.txt\n",
            "label -> __label__\n",
            "loss -> loss_name.softmax\n",
            "lr -> 0.05246053864839083\n",
            "lrUpdateRate -> 100\n",
            "maxn -> 6\n",
            "minCount -> 1\n",
            "minCountLabel -> 0\n",
            "minn -> 3\n",
            "model -> model_name.supervised\n",
            "neg -> 5\n",
            "output -> \n",
            "pretrainedVectors -> \n",
            "qnorm -> False\n",
            "qout -> False\n",
            "retrain -> False\n",
            "saveOutput -> False\n",
            "seed -> 0\n",
            "setManual -> <bound method PyCapsule.setManual of <fasttext_pybind.args object at 0x0000017536C90730>>\n",
            "t -> 0.0001\n",
            "thread -> 15\n",
            "verbose -> 2\n",
            "wordNgrams -> 3\n",
            "ws -> 5\n"
          ]
        }
      ],
      "source": [
        "args_obj = model5.f.getArgs()\n",
        "for hparam in dir(args_obj):\n",
        "    if not hparam.startswith('__'):\n",
        "        print(f\"{hparam} -> {getattr(args_obj, hparam)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400000, 0.9421525, 0.9421525)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3 hour optimization\n",
        "model6 = fasttext.train_supervised(input='train.ft.txt', autotuneValidationFile='test.ft.txt', autotuneDuration=10800)\n",
        "model6.test(\"test.ft.txt\", k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "autotuneDuration -> 10800\n",
            "autotuneMetric -> f1\n",
            "autotuneModelSize -> \n",
            "autotunePredictions -> 1\n",
            "autotuneValidationFile -> test.ft.txt\n",
            "bucket -> 10000000\n",
            "cutoff -> 0\n",
            "dim -> 31\n",
            "dsub -> 2\n",
            "epoch -> 4\n",
            "input -> train.ft.txt\n",
            "label -> __label__\n",
            "loss -> loss_name.softmax\n",
            "lr -> 0.03466143057439238\n",
            "lrUpdateRate -> 100\n",
            "maxn -> 0\n",
            "minCount -> 1\n",
            "minCountLabel -> 0\n",
            "minn -> 0\n",
            "model -> model_name.supervised\n",
            "neg -> 5\n",
            "output -> \n",
            "pretrainedVectors -> \n",
            "qnorm -> False\n",
            "qout -> False\n",
            "retrain -> False\n",
            "saveOutput -> False\n",
            "seed -> 0\n",
            "setManual -> <bound method PyCapsule.setManual of <fasttext_pybind.args object at 0x0000017536C90A70>>\n",
            "t -> 0.0001\n",
            "thread -> 15\n",
            "verbose -> 2\n",
            "wordNgrams -> 3\n",
            "ws -> 5\n"
          ]
        }
      ],
      "source": [
        "args_obj = model6.f.getArgs()\n",
        "for hparam in dir(args_obj):\n",
        "    if not hparam.startswith('__'):\n",
        "        print(f\"{hparam} -> {getattr(args_obj, hparam)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ProjectInc1_BGilmore.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "86baf25e75fbd73317f93b642c2c74dd99b797494ca42a827a99f936e54713f4"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
